{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "True\n",
      "1\n",
      "NVIDIA A100-PCIE-40GB\n",
      "3.10.15 (main, Oct  3 2024, 07:27:34) [GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "import transformers\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "# print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import *\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import time\n",
    "import json\n",
    "import transformers\n",
    "\n",
    "device=\"cuda\"\n",
    "\n",
    "# 加载文档\n",
    "def load_documents(directory='/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/data/wiki.train.txt'):\n",
    "    if \"popQA\" in directory:\n",
    "        text_splitter=RecursiveCharacterTextSplitter(separators=[\"\\n\"])\n",
    "        with open(directory, 'r', encoding='utf-8') as file:\n",
    "            texts=file.readlines()\n",
    "        decuments=text_splitter.create_documents(texts=texts)   \n",
    "        return decuments\n",
    "    loader = TextLoader(directory)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=30)\n",
    "    text_splitter=RecursiveCharacterTextSplitter(separators=\"\\n\")\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    return split_docs\n",
    "\n",
    "\n",
    "# 加载embedding模型\n",
    "def load_embedding_model(model_path='/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/models/bge-large-en-v1.5'):\n",
    "    embedding_model = HuggingFaceEmbeddings(  # embedding 模型\n",
    "        model_name=model_path,\n",
    "        model_kwargs={'device': device},\n",
    "        encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "    return embedding_model\n",
    "\n",
    "\n",
    "def load_llama(model_path='/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/models/Llama-2-7b-chat-hf'):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        return_dict=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map={\"\": device},\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    model = base_model.eval()\n",
    "    return model, tokenizer\n",
    "def load_Qwen(model_path=\"/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/models/Qwen2.5-7B-Instruct\"):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map={'':device}\n",
    "    )\n",
    "    model=model.eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def load_qa(dataset_path='/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/data/NQ-dev.json'):\n",
    "    if \"PopQA\" in dataset_path:\n",
    "        dataset=load_from_disk(dataset_path)\n",
    "        return dataset['question'],dataset['possible_answers']\n",
    "    question = []\n",
    "    answer = []\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                # 使用json.loads()解析每个JSON对象\n",
    "                data = json.loads(line)\n",
    "                # 处理JSON数据\n",
    "                question.append(data['question'])\n",
    "                answer.append((data['answer']))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "    return question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd6e8a0e2924eb4b2298a5dd7ad012b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_model = load_embedding_model()\n",
    "knowledge_dir='/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/data/popQA_knowledge'\n",
    "knowledge_file_dir='/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/data/popQA_knowledge.txt'\n",
    "if not os.path.exists(knowledge_dir):\n",
    "    documents = load_documents(knowledge_file_dir)\n",
    "    vector_store = FAISS.from_documents(documents, embedding_model)\n",
    "    vector_store.save_local(knowledge_dir)\n",
    "else:\n",
    "    # 如果本地已经有faiss仓库了，说明之前已经保存过了，就直接读取\n",
    "    vector_store = FAISS.load_local(knowledge_dir, embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "questions, answers = load_qa(\"/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/data/PopQA\")\n",
    "# model, tokenizer = load_Qwen(\"/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/models/Qwen2.5-7B-Instruct\")\n",
    "model, tokenizer = load_llama(\"/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/models/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_Qwen(question, model, tokenizer, vector_store, device,rag=False):\n",
    "    if rag:\n",
    "        docs=vector_store.similarity_search(question, k=6)  # 计算相似度，并把相似度高的chunk放在前面\n",
    "        contexts = [doc.page_content for doc in docs]\n",
    "        contexts_text=\"\\n\".join(contexts)       \n",
    "        system_prompt = f\"You are now playing the role of the encyclopedia. Answer my questions without any unnecessary words.Here is some knowledge you can refer to:\\n{contexts_text}\"   \n",
    "    else:\n",
    "        system_prompt = \"You are now playing the role of the encyclopedia. Answer my questions without any unnecessary words.\"\n",
    "    if not question.endswith(\"?\"):\n",
    "        question = question + \"?\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=512\n",
    "        )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    if rag:\n",
    "        return response,contexts\n",
    "    else:\n",
    "        return response\n",
    "def get_answer_llama2(question, model, tokenizer, vector_store, device, k=6, rag=False):\n",
    "    if not question.endswith(\"?\"):\n",
    "        question = question + \"?\"\n",
    "    if rag and k>0:\n",
    "        docs=vector_store.similarity_search(question, k=6)  # 计算相似度，并把相似度高的chunk放在前面\n",
    "        contexts = [doc.page_content for doc in docs]\n",
    "        contexts_text=\"\\n\".join(contexts)\n",
    "        input=f\"<s>[INST] <<SYS>>\\nYou are now playing the role of the encyclopedia. Answer my questions without any unnecessary words.\\nYou can use the following knowledge but don't be misled by inaccurate content:\\n{contexts_text}\\n<</SYS>>nQuestion:\\n{question}\\nAnswer: [/INST]\"       \n",
    "    else:\n",
    "        input = f\"<s>[INST] <<SYS>>\\nYou are now playing the role of the encyclopedia. Answer my questions without any unnecessary words.\\n<</SYS>>\\nQuestion:\\n{question}\\nAnswer: [/INST]\"\n",
    "    inputs = tokenizer(input, return_tensors='pt', max_length=4000, truncation=True)\n",
    "    if inputs[\"input_ids\"].shape[1] > 3900:\n",
    "        return get_answer_llama2(question, model, tokenizer, vector_store, device, k=k-1, rag=rag)\n",
    "    with torch.no_grad():\n",
    "        generate_ids = model.generate(input_ids=inputs[\"input_ids\"].to(device),max_new_tokens=50)\n",
    "    ans_text=tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    ans_text=ans_text.split(\"[/INST]\")[1].strip()\n",
    "    if rag:\n",
    "        if k<=0:\n",
    "            return ans_text,[]\n",
    "        return ans_text,contexts\n",
    "    else:\n",
    "        return ans_text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Heath's occupation?\n",
      "[\"songwriter\", \"song writer\"]\n",
      "answer:\n",
      " Heath's occupation: Actor\n",
      "answer_rag:\n",
      " Heath is a bassist, composer, singer, and songwriter.\n",
      "contexts:\n",
      " [\"Heath: Japanese musician (1968-2023), alias: ['Hiroshi Morie'], instance of: ['human'], image: ['Heath (musician) in São Paulo, Brazil 2011-11-09.jpg532 × 800; 340 KB'], sex or gender: ['male'], country of citizenship: ['Japan'], name in native language: ['HEATH (Japanese)'], birth name: ['森江 博 (Japanese)'], given name: ['Hiroshi'], date of birth: ['22 January 1968'], place of birth: ['Amagasaki'], date of death: ['29 October 2023'], manner of death: ['natural causes'], cause of death: ['colorectal cancer'], languages spoken, written or signed: ['Japanese'], occupation: ['bassist', 'composer', 'singer', 'songwriter'], work period (start): ['1986'], work period (end): ['2023'], blood type: ['B'], instrument: ['bass guitar', 'guitar', 'voice'], member of: ['X Japan'], genre: ['heavy metal'], official website: ['http://www.heath.co.jp/', 'https://heathproject.com/'], Commons category: ['Heath (musician)'], Europeana entity: ['agent/base/59801'], Freebase ID: ['/m/01vrw2r'], MusicBrainz artist ID: ['f9b3fd5e-535e-4d48-840b-0c626e6f16f6'], Songkick artist ID: ['504782'], WikiTree person ID: ['森江-1']\", \"The Lab: book by Jack Heath, , instance of: ['literary work'], title: ['The Lab (English)'], followed by: ['Remote control'], genre: ['science fiction', 'espionage novel'], creator: ['Jack Heath'], author: ['Jack Heath'], publisher: ['Scholastic Corporation'], country of origin: ['Australia'], language of work or name: ['English'], publication date: ['1 November 2008'], ISBN-13: ['978-1-74262-389-4'], Goodreads version/edition ID: ['34310789'], Goodreads work ID: ['5400228'], ISFDB title ID: ['1114900']\", 'Alastair Heathcote: British rower, alias: [\\'Alastair Robert Heathcote\\'], instance of: [\\'human\\'], sex or gender: [\\'male\\'], country of citizenship: [\\'United Kingdom\\'], given name: [\\'Alastair\\'], family name: [\\'Heathcote\\'], date of birth: [\\'18 August 1977\\'], place of birth: [\\'Athens\\'], father: [\\'Sir Mark Heathcote, 10th Baronet\\'], mother: [\\'Susan Mary Ashley\\'], languages spoken, written or signed: [\\'English\\'], occupation: [\\'rower\\'], educated at: [\\'Eton College\\', \\'Oxford Brookes University\\', \\'Newcastle University\\'], mass: [\\'92 kilogram\\'], sport: [\\'rowing\\'], sports discipline competed in: [\\'rowing\\'], participant in: [\"rowing at the 2008 Summer Olympics – men\\'s eight\"], conflict: [\\'Iraq War\\'], military branch: [\\'British Army\\'], height: [\\'191 centimetre\\'], Companies House officer ID: [\\'q-6r2CybFAXPiXc8uGEYeW2dfqQ\\', \\'rLbymLSEs8OhYcKQPN4vx7a8exQ\\', \\'7PWBT8eeaMAV4JjbOvrKW2ggNg8\\', \\'yGm7PXDXvxk0iyfyyHHQIKJtgTE\\'], Freebase ID: [\\'/m/02z19vb\\'], Olympedia people ID: [\\'118112\\'], Olympic.org athlete ID (archived): [\\'alastair-heathcote\\'], Olympics.com athlete ID: [\\'alastair-heathcote\\'], Prabook ID: [\\'2555132\\'], Sports-Reference.com Olympic athlete ID (archived): [\\'he/alastair-heathcote-1\\'], Team GB athlete ID: [\\'alastair-heathcote\\', \\'4jPOZCJUGRWDFlEterHNzD\\'], World Rowing ID: [\\'30085\\'], World Rowing UUID: [\\'d2c5b9dd-6f0e-4837-a07a-c4c446c7e438\\'], The Peerage person ID: [\\'p42258.htm#i422574\\']', \"Maurice Laing: British businessman, alias: ['Sir John Maurice Laing'], instance of: ['human'], sex or gender: ['male'], given name: ['Maurice'], date of birth: ['1 February 1918Gregorian'], date of death: ['22 February 2008'], father: ['John Laing'], occupation: ['military personnel'], educated at: ['St Lawrence College'], military branch: ['Royal Air Force'], award received: ['Knight Bachelor'], Freebase ID: ['/m/03qkq3y'], Oxford Dictionary of National Biography ID: ['99987'], Prabook ID: ['1306743']\", \"bhikkhu: fully ordained male Buddhist monastic, alias: ['bhikṣu', 'Buddhist monk', 'monk', 'bhikshu', 'bonze'], instance of: ['religious occupation'], subclass of: ['monk', 'Buddhist clergy', 'mendicant'], part of: ['seven classes of disciples'], image: ['Phutthamonthon Buddha.JPG1,280 × 960; 310 KB'], religion or worldview: ['Buddhism'], field of this occupation: ['Buddhism'], described by source: ['A Dictionary of Chinese Buddhist Terms', 'Brockhaus and Efron Encyclopedic Dictionary', 'The Nuttall Encyclopædia', 'Encyclopædia Britannica 11th edition'], has characteristic: ['clerical celibacy', 'male'], female form of label: ['راهبة بوذية (Arabic)'], male form of label: ['monaco buddhista (Italian)'], opposite of: ['bhikkhunī'], different from: ['Mnich'], Commons category: ['Buddhist monks'], topic's main category: ['Category:Buddhist monks'], Bibliothèque nationale de France ID: ['119633479'], J9U ID: ['987007292532405171'], Library of Congress authority ID: ['sh85017569'], NL CR AUT ID: ['ph174203'], AniDB tag ID: ['221'], BabelNet ID: ['03227082n'], BNCF Thesaurus ID: ['11069'], Encyclopædia Britannica Online ID: ['topic/bhikku'], Encyclopædia Universalis ID: ['bhiksu'], Encyclopedia of China (Third Edition) ID: ['216982'], Encyclopedia of Korean Culture ID: ['E0025091'], Freebase ID: ['/m/02cf4x'], Great Russian Encyclopedia Online ID (old version): ['1892208'], Great Russian Encyclopedia portal ID: ['bkhikkkhu-703986'], KBpedia ID: ['Bhikkhu'], Namuwiki ID: ['승려'], Store norske leksikon ID: ['bhikkhu']\", \"Niall Toner: Bluegrass musician, , instance of: ['human'], sex or gender: ['male'], country of citizenship: ['Ireland'], given name: ['Niall'], family name: ['Toner'], date of birth: ['1944'], place of birth: ['Dublin'], occupation: ['mandolinist', 'songwriter'], work period (start): ['1970'], instrument: ['mandolin'], genre: ['bluegrass music'], Discogs artist ID: ['1915265'], Europeana entity: ['agent/base/130727'], Freebase ID: ['/m/0h93y1l']\"]\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 30\n",
    "print(questions[sample_idx])\n",
    "print(answers[sample_idx])\n",
    "answer = get_answer_llama2(questions[sample_idx], model, tokenizer, vector_store, device,rag=False)\n",
    "print(\"answer:\\n\",answer)\n",
    "answer_rag,contexts = get_answer_llama2(questions[sample_idx], model, tokenizer, vector_store, device,rag=True)\n",
    "print(\"answer_rag:\\n\",answer_rag)\n",
    "print(\"contexts:\\n\",contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is George Rankin's occupation?\n",
      "[\"politician\", \"political leader\", \"political figure\", \"polit.\", \"pol\"]\n",
      "George Rankin's occupation is:\n",
      "\n",
      "Banker\n",
      "George Rankin's occupation is politician.\n",
      "----------------------------\n",
      "What is John Mayne's occupation?\n",
      "[\"journalist\", \"journo\", \"journalists\"]\n",
      "John Mayer's occupation is musician.\n",
      "John Mayne's occupation is journalist, poet, and writer.\n",
      "----------------------------\n",
      "What is Henry Feilden's occupation?\n",
      "[\"politician\", \"political leader\", \"political figure\", \"polit.\", \"pol\"]\n",
      "Henry Fielding's occupation is: Author\n",
      "Henry Feilden's occupation is listed as \"Politician\".\n",
      "----------------------------\n",
      "What is Kathy Saltzman's occupation?\n",
      "[\"politician\", \"political leader\", \"political figure\", \"polit.\", \"pol\"]\n",
      "Kathy Saltzman's occupation is artist.\n",
      "Kathy Saltzman's occupation is member of the State Senate of Minnesota.\n",
      "----------------------------\n",
      "What is Eleanor Davis's occupation?\n",
      "[\"cartoonist\", \"graphic artist\", \"animator\", \"illustrator\"]\n",
      "Davis - cartoonist\n",
      "Eleanor Davis is a comics artist and illustrator.\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "qa_out_dataset_path = \"/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/data/PopQA_100_llama2_output\"\n",
    "dataset_out = load_from_disk(qa_out_dataset_path)\n",
    "for i in range(5):\n",
    "    print(dataset_out['question'][i])\n",
    "    print(dataset_out['possible_answers'][i])\n",
    "    print(dataset_out['answer_plain'][i])\n",
    "    print(dataset_out['answer_rag'][i])\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascscasc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('ascSCASC'.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Henry Feilden's occupation?\n",
      "[\"politician\", \"political leader\", \"political figure\", \"polit.\", \"pol\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:\n",
      " Henry Feilding was an English politician and poet.\n",
      "answer_rag:\n",
      " Henry Feilden's occupation was politician.\n",
      "contexts:\n",
      " [\"Henry Feilden: British politician, alias: ['Henry Master Feilden'], instance of: ['human'], sex or gender: ['male'], country of citizenship: ['United Kingdom of Great Britain and Ireland'], name in native language: ['Henry Master Feilden (English)'], given name: ['Henry'], family name: ['Feilden'], date of birth: ['21 February 1818Gregorian'], date of death: ['5 September 1875Gregorian'], father: ['Joseph Feilden'], mother: ['Frances Mary Master'], spouse: ['Caroline Mosley'], child: ['Frances Sophia Feilden'], languages spoken, written or signed: ['English'], occupation: ['politician'], position held: ['member of the 21st Parliament of the United Kingdom', 'member of the 20th Parliament of the United Kingdom'], work location: ['London'], member of political party: ['Conservative Party'], candidacy in election: ['1874 United Kingdom general election'], Freebase ID: ['/m/0g5797g'], Hansard (1803–2005) ID: ['mr-henry-feilden'], Prabook ID: ['2344865'], Rush Parliamentary Archive ID: ['1586'], TheyWorkForYou ID: ['15059'], Geni.com profile ID: ['6000000040969185862'], The Peerage person ID: ['p68219.htm#i682189'], WikiTree person ID: ['Feilden-22']\", \"John Muse: American businessman, , instance of: ['human'], sex or gender: ['male'], country of citizenship: ['United States of America'], given name: ['John'], place of birth: ['Fort Worth'], occupation: ['polo player', 'businessperson'], educated at: ['United States Air Force Academy'], residence: ['Highland Park'], sport: ['polo'], Freebase ID: ['/m/03wqjk1']\", 'Henry Moule: English inventor (1801-1880), , instance of: [\\'human\\'], sex or gender: [\\'male\\'], country of citizenship: [\\'United Kingdom of Great Britain and Ireland\\'], given name: [\\'Henry\\'], family name: [\\'Moule\\'], date of birth: [\\'27 January 1801Gregorian\\'], place of birth: [\\'Melksham\\'], date of death: [\\'3 February 1880Gregorian\\'], place of death: [\\'Dorset\\'], child: [\\'Charles Walter Moule\\', \\'George Moule\\', \\'Arthur Moule\\'], occupation: [\\'inventor\\', \\'ecologist\\'], educated at: [\"St John\\'s College\", \\'Marlborough Royal Free Grammar School\\'], religion or worldview: [\\'Anglicanism\\'], described by source: [\\'Dictionary of National Biography, 1885–1900\\'], VIAF ID: [\\'31578919\\'], ISNI: [\\'0000000073928900\\'], FAST ID: [\\'355410\\'], Library of Congress authority ID: [\\'no95022211\\'], WorldCat Entities ID: [\\'E39PBJpjhFDXtTKw4PQgwpYHG3\\'], Cambridge Alumni Database ID: [\\'ML817H\\'], Freebase ID: [\\'/m/03cq4dh\\'], Hymnary author ID: [\\'Moule_H1\\'], Open Library ID: [\\'OL5159144A\\'], Oxford Dictionary of National Biography ID: [\\'19426\\'], SNAC ARK ID: [\\'w6hv2dq7\\'], WeRelate person ID: [\\'Henry_Moule_(1)\\'], WikiTree person ID: [\\'Moule-23\\']', \"Bruce Charles Heezen: American geologist (1924-1977), alias: ['Bruce C. Heezen'], instance of: ['human'], sex or gender: ['male'], country of citizenship: ['United States of America'], name in native language: ['Bruce C. Heezen (English)'], given name: ['Bruce'], family name: ['Heezen'], date of birth: ['11 April 1924Gregorian'], place of birth: ['Vinton'], date of death: ['21 June 1977'], place of death: ['ocean'], languages spoken, written or signed: ['English'], occupation: ['oceanographer', 'geologist'], field of work: ['geology'], employer: ['Columbia University'], educated at: ['University of Iowa', 'Columbia University'], partner in business or sport: ['Marie Tharp'], award received: ['Cullum Geographical Medal', 'Walter H. Bucher Medal', 'Henry Bryant Bigelow Medal in Oceanography', 'Francis P. Shepard Medal'], Commons category: ['Bruce C. Heezen'], VIAF ID: ['16014349'], ISNI: ['0000000115998115'], NORAF ID: ['90248844'], Canadiana Name Authority ID: ['ncf10095436'], GND ID: ['1089097050'], FAST ID: ['9079'], J9U ID: ['987007435486705171'], Library of Congress authority ID: ['n50027405'], NL CR AUT ID: ['ola364083'], Libraries Australia ID: ['35184114'], Nationale Thesaurus voor Auteursnamen ID: ['072895675'], NUKAT ID: ['n2002097116'], RERO ID (obsolete): ['02-A003357668'], IdRef ID: ['069103232'], WorldCat Entities ID: ['E39PBJc3Fj7DjJ397WrGH4t7pP'], American National Biography ID: ['1302084'], Encyclopædia Britannica contributor ID: ['1283'], Encyclopædia Universalis ID: ['bruce-c-heezen'], Freebase ID: ['/m/012jmk'], NE.se ID: ['bruce-c-heezen'], NLA Trove people ID: ['855768'], openMLOL author ID: ['275170'], Oxford Reference overview ID: ['20110803095928242'], Prabook ID: ['2480444'], SNAC ARK ID: ['w6k07787'], U.S. National Archives Identifier: ['10582572']\", \"Henry Tizard: British chemist, alias: ['Sir Henry Thomas Tizard'], instance of: ['human'], sex or gender: ['male'], country of citizenship: ['United Kingdom'], given name: ['Henry', 'Thomas'], family name: ['Tizard'], date of birth: ['23 August 1885Gregorian'], place of birth: ['Gillingham'], date of death: ['9 October 1959'], place of death: ['Fareham'], place of burial: ['Oriel College'], father: ['Thomas Henry Tizard'], mother: ['Mary Elizabeth Churchward'], child: ['Richard Henry Tizard', 'Peter Tizard'], number of children: ['3'], languages spoken, written or signed: ['English'], occupation: ['chemist', 'mathematician'], field of work: ['chemistry'], employer: ['Imperial College London', 'Magdalen College', 'Ministry of Defence of the United Kingdom'], position held: ['rector', 'rector', 'Chief Scientific Adviser to the Ministry of Defence'], educated at: ['Magdalen College', 'Westminster School'], military or police rank: ['lieutenant colonel'], member of: ['Royal Society'], award received: ['Fellow of the Royal Society', 'Albert Medal', 'Companion of the Order of the Bath', 'Knight Commander of the Order of the Bath', 'Knight Grand Cross of the Order of the Bath', 'Franklin Medal', 'Air Force Cross', 'Knight Bachelor'], VIAF ID: ['54958064'], ISNI: ['0000000073746816'], BAnQ authority ID: ['0000357116'], NORAF ID: ['6005560'], Bibliothèque nationale de France ID: ['16728754d'], Canadiana Name Authority ID: ['ncf10400288'], GND ID: ['119438798'], FAST ID: ['1761618'], J9U ID: ['987007278734205171'], Library of Congress authority ID: ['n85800968'], National Library of Ireland ID: ['vtls001308519'], Nationale Thesaurus voor Auteursnamen ID: ['071368418'], PLWABN ID: ['9810554476305606'], IdRef ID: ['122110773'], WorldCat Entities ID: ['E39PBJrKQ6x9PGJxyR8TDVgdwC'], Archive Site Trinity College Cambridge ID: ['tizard-sir-henry-thomas-1885-1959-knight-physical-chemist-and-science-administrator'], Freebase ID: ['/m/02wqpd'], Museo Galileo authority ID: ['191821'], National Library of Israel ID (old): ['000477511'], National Portrait Gallery (London) person ID: ['mp56537'], Open Library ID: ['OL2419222A'], Oxford Dictionary of National Biography ID: ['36528'], Oxford Reference overview ID: ['20110803104753224'], past Fellow of the Royal Society ID: ['NA8290'], PM20 folder ID: ['pe/063281'], SHARE Catalogue author ID: ['16916'], SNAC ARK ID: ['w6cz394j'], UK National Archives ID: ['F64686'], WBIS ID: ['B1805344'], Find a Grave memorial ID: ['13813422'], The Peerage person ID: ['p65077.htm#i650764'], WikiTree person ID: ['Tizard-18']\", \"Bedřich Feigl: Czech painter (1884-1965), alias: ['Fred Feigl', 'Freidrich Feigl', 'Bedrich Feigl', 'Friedrich Feigl', 'Frederick Feigl', 'friedrich feigl', 'f. feigl', 'Fedrich Feigl'], instance of: ['human'], signature: ['Bedřich Feigl signatura.jpg345 × 113; 10 KB'], sex or gender: ['male'], country of citizenship: ['Czechoslovakia', 'Cisleithania'], given name: ['Bedřich'], family name: ['Feigl'], date of birth: ['6 March 1884Gregorian'], place of birth: ['Prague'], date of death: ['19 December 1965', '17 December 1965'], place of death: ['London'], sibling: ['Hugo Feigl', 'Karel Feigl', 'Ernst Feigl', 'Irena Feiglová', 'Kamila Feiglová'], occupation: ['graphic designer', 'painter', 'printmaker', 'visual artist', 'illustrator', 'graphic artist'], educated at: ['Academy of Fine Arts, Prague'], on focus list of Wikimedia project: ['WikiProject PCC Wikidata Pilot/Frick Art Reference Library', 'WikiProject New York Public Library'], copyright representative: ['reproduction right not represented by CISAC member'], has works in the collection: ['Museum of Modern Art', 'Moravian Gallery in Brno', 'National Gallery Prague', 'Print Collection'], copyright status as a creator: ['works protected by copyrights'], artist files at: ['Frick Art Research Library'], Commons category: ['Bedřich Feigl'], VIAF ID: ['52752167'], ISNI: ['0000000073284623'], GND ID: ['128853034'], Deutsche Biographie (GND) ID: ['128853034'], DDB person ID: ['128853034'], FAST ID: ['1490089'], J9U ID: ['987007312237605171'], Union List of Artist Names ID: ['500129587'], Library of Congress authority ID: ['n88236985'], NL CR AUT ID: ['jn20000400666'], Nationale Thesaurus voor Auteursnamen ID: ['069389195'], NUKAT ID: ['n01028655'], IdRef ID: ['184315212'], WorldCat Entities ID: ['E39PBJrcjWQycb996cH3kCdWjC'], abART person ID: ['16800'], AKL Online artist ID: ['00634303'], Art UK artist ID: ['feigl-friedrich-18841965'], artist-info artist ID: ['279534'], Artnet artist ID: ['friedrich-bedrich-feigl'], askArt person ID: ['11030269'], Athenaeum person ID: ['14708'], BHCL UUID: ['a050eed4-b42a-4f31-9a66-7cded4724d55'], Biographical Dictionary of the Czech Lands ID: ['54847'], Bridgeman artist ID: ['57793'], Christie's creator ID: ['21699'], DACS ID (2022): ['008315'], DACS ID (former): ['18635629-b621-e111-9c2b-000c29604b72'], DoME artist ID: ['122'], Europeana entity: ['agent/base/55475'], FactGrid item ID: ['Q224412'], Freebase ID: ['/m/0g57hn8'], Frick Art Research Library Artist File ID: ['991005050879707141'], Invaluable.com person ID: ['s6y9zwijha'], Jewish Museum Berlin person ID: ['jmb-pers-12587'], Kallías ID: ['PE00173299'], Museum of Modern Art artist ID: ['1827'], MutualArt artist ID: ['22861FEB6B702DEA'], Prabook ID: ['2461080'], RKDartists ID: ['217646'], SNAC ARK ID: ['w68j22h4'], Web umenia creator ID: ['1714554'], Geni.com profile ID: ['6000000065561488942']\"]\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 2\n",
    "print(questions[sample_idx])\n",
    "print(answers[sample_idx])\n",
    "answer = get_answer_Qwen(questions[sample_idx], model, tokenizer, vector_store, device,rag=False)\n",
    "print(\"answer:\\n\",answer)\n",
    "answer_rag,contexts = get_answer_Qwen(questions[sample_idx], model, tokenizer, vector_store, device,rag=True)\n",
    "print(\"answer_rag:\\n\",answer_rag)\n",
    "print(\"contexts:\\n\",contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70ed7dfa4334fc38a69ed53a6a6d408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/14267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec158202c264cfeb971812b896504b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "dataset=load_from_disk(\"/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/data/PopQA\")\n",
    "dataset=dataset.filter(lambda x,idx:idx<100,with_indices=True)\n",
    "dataset.save_to_disk(\"/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/data/PopQA_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                        subj        prop          obj  subj_id  \\\n",
      "0      4222362               George Rankin  occupation   politician  1850297   \n",
      "1      4725190                  John Mayne  occupation   journalist  2079053   \n",
      "2      4382392               Henry Feilden  occupation   politician  1925450   \n",
      "3      4822110              Kathy Saltzman  occupation   politician  2122743   \n",
      "4      4011112               Eleanor Davis  occupation   cartoonist  1752619   \n",
      "...        ...                         ...         ...          ...      ...   \n",
      "14262  4165948                 Netherlands     capital    Amsterdam  1825504   \n",
      "14263  2617063  City Municipality of Celje     capital        Celje  1127153   \n",
      "14264   471864                       Delhi     capital    New Delhi   192624   \n",
      "14265  2965573     Palestinian territories     capital    Jerusalem  1270077   \n",
      "14266   802449                   Louisiana     capital  Baton Rouge   342549   \n",
      "\n",
      "       prop_id   obj_id                                          s_aliases  \\\n",
      "0           22  2834605                            [\"George James Rankin\"]   \n",
      "1           22   663400                                                 []   \n",
      "2           22  2834605                           [\"Henry Master Feilden\"]   \n",
      "3           22  2834605                                                 []   \n",
      "4           22    68412                       [\"Eleanor McCutcheon Davis\"]   \n",
      "...        ...      ...                                                ...   \n",
      "14262      422  2455815  [\"Holland\",\"the Netherlands\",\"NL\",\"NED\",\"Neder...   \n",
      "14263      422     5035                        [\"Celje city municipality\"]   \n",
      "14264      422  2938512         [\"National Capital Region of Delhi\",\"NCR\"]   \n",
      "14265      422   127625  [\"occupied Palestinian territories\",\"OPT\",\"Wes...   \n",
      "14266      422   940158  [\"LA\",\"State of Louisiana\",\"18th State\",\"Louis...   \n",
      "\n",
      "                                               o_aliases  \\\n",
      "0      [\"political leader\",\"political figure\",\"polit....   \n",
      "1                               [\"journo\",\"journalists\"]   \n",
      "2      [\"political leader\",\"political figure\",\"polit....   \n",
      "3      [\"political leader\",\"political figure\",\"polit....   \n",
      "4            [\"graphic artist\",\"animator\",\"illustrator\"]   \n",
      "...                                                  ...   \n",
      "14262  [\"Mokum\",\"Amsterdam, NL\",\"Amsterdam, Netherlan...   \n",
      "14263                                                 []   \n",
      "14264                [\"New Delhi district\",\"Nayi Dilli\"]   \n",
      "14265  [\"Yerushalayim\",\"J'lem\",\"Aelia Capitolina\",\"Al...   \n",
      "14266  [\"Baton Rouge, Louisiana\",\"Baton Rouge, LA\",\"B...   \n",
      "\n",
      "                                         s_uri  \\\n",
      "0      http://www.wikidata.org/entity/Q5543720   \n",
      "1      http://www.wikidata.org/entity/Q6247345   \n",
      "2      http://www.wikidata.org/entity/Q5725578   \n",
      "3      http://www.wikidata.org/entity/Q6377295   \n",
      "4      http://www.wikidata.org/entity/Q5354261   \n",
      "...                                        ...   \n",
      "14262       http://www.wikidata.org/entity/Q55   \n",
      "14263  http://www.wikidata.org/entity/Q3441823   \n",
      "14264     http://www.wikidata.org/entity/Q1353   \n",
      "14265   http://www.wikidata.org/entity/Q407199   \n",
      "14266     http://www.wikidata.org/entity/Q1588   \n",
      "\n",
      "                                         o_uri  \\\n",
      "0        http://www.wikidata.org/entity/Q82955   \n",
      "1      http://www.wikidata.org/entity/Q1930187   \n",
      "2        http://www.wikidata.org/entity/Q82955   \n",
      "3        http://www.wikidata.org/entity/Q82955   \n",
      "4      http://www.wikidata.org/entity/Q1114448   \n",
      "...                                        ...   \n",
      "14262      http://www.wikidata.org/entity/Q727   \n",
      "14263     http://www.wikidata.org/entity/Q1012   \n",
      "14264      http://www.wikidata.org/entity/Q987   \n",
      "14265     http://www.wikidata.org/entity/Q1218   \n",
      "14266    http://www.wikidata.org/entity/Q28218   \n",
      "\n",
      "                                  s_wiki_title            o_wiki_title  \\\n",
      "0                                George Rankin              Politician   \n",
      "1                                   John Mayne              Journalist   \n",
      "2      Henry Feilden (Conservative politician)              Politician   \n",
      "3                               Kathy Saltzman              Politician   \n",
      "4                                Eleanor Davis              Cartoonist   \n",
      "...                                        ...                     ...   \n",
      "14262                              Netherlands               Amsterdam   \n",
      "14263               City Municipality of Celje                   Celje   \n",
      "14264                                    Delhi               New Delhi   \n",
      "14265                  Palestinian territories               Jerusalem   \n",
      "14266                                Louisiana  Baton Rouge, Louisiana   \n",
      "\n",
      "        s_pop   o_pop                                           question  \\\n",
      "0         142   25692                What is George Rankin's occupation?   \n",
      "1         236   24952                   What is John Mayne's occupation?   \n",
      "2          58   25692                What is Henry Feilden's occupation?   \n",
      "3         127   25692               What is Kathy Saltzman's occupation?   \n",
      "4         317    9649                What is Eleanor Davis's occupation?   \n",
      "...       ...     ...                                                ...   \n",
      "14262  416350  147710                What is the capital of Netherlands?   \n",
      "14263     335    4086  What is the capital of City Municipality of Ce...   \n",
      "14264  219227  128193                      What is the capital of Delhi?   \n",
      "14265   17545  136734    What is the capital of Palestinian territories?   \n",
      "14266  242631   39365                  What is the capital of Louisiana?   \n",
      "\n",
      "                                        possible_answers  \n",
      "0      [\"politician\", \"political leader\", \"political ...  \n",
      "1                [\"journalist\", \"journo\", \"journalists\"]  \n",
      "2      [\"politician\", \"political leader\", \"political ...  \n",
      "3      [\"politician\", \"political leader\", \"political ...  \n",
      "4      [\"cartoonist\", \"graphic artist\", \"animator\", \"...  \n",
      "...                                                  ...  \n",
      "14262  [\"The Hague\", \"Den Haag\", \"'s-Gravenhage\", \"Ha...  \n",
      "14263                                          [\"Celje\"]  \n",
      "14264  [\"New Delhi\", \"New Delhi district\", \"Nayi Dilli\"]  \n",
      "14265  [\"Jerusalem\", \"Yerushalayim\", \"J'lem\", \"Aelia ...  \n",
      "14266  [\"Baton Rouge\", \"Baton Rouge, Louisiana\", \"Bat...  \n",
      "\n",
      "[14267 rows x 17 columns]\n",
      "Dataset({\n",
      "    features: ['id', 'subj', 'prop', 'obj', 'subj_id', 'prop_id', 'obj_id', 's_aliases', 'o_aliases', 's_uri', 'o_uri', 's_wiki_title', 'o_wiki_title', 's_pop', 'o_pop', 'question', 'possible_answers'],\n",
      "    num_rows: 14267\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,Dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/mnt/data/chenjinwen/AI-Security-Evaluation_RAG/data/PopQA/test.tsv\", sep='\\t')\n",
    "df = pd.DataFrame(df)\n",
    "print(df)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "print(dataset)\n",
    "# print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "William Collins , English landscape and genre painter (1788-1847) , ['William, II Collins', 'William II Collins', 'W. Collins', 'R.A. W. Collins', 'William W. Collins', 'William Collins R. A.', 'Collins', 'R.A. Collins']\n",
      "90\n",
      "90\n",
      "instance of ['human', 'Russian Wikipedia']\n",
      "------------------\n",
      "image ['John Linnell - William Collins, R.A. - Google Art Project.jpg4,291 × 5,394; 3.1 MB', 'Commons Creator page']\n",
      "------------------\n",
      "sex or gender ['male', 'Swedish Wikipedia', 'Virtual International Authority File', '28432019', '4 November 2018']\n",
      "------------------\n",
      "country of citizenship ['United Kingdom of Great Britain and Ireland', 'Kingdom of Great Britain', '1 January 1801Gregorian', 'Acts of Union 1800']\n",
      "------------------\n",
      "name in native language ['William Collins (English)']\n",
      "------------------\n",
      "given name ['William']\n",
      "------------------\n",
      "family name ['Collins']\n",
      "------------------\n",
      "date of birth ['8 September 1788Gregorian', 'SNAC', 'w60p13nv', 'William Collins (painter)', '9 October 2017']\n",
      "------------------\n",
      "place of birth ['London', 'Wikimedia Commons']\n",
      "------------------\n",
      "date of death ['17 February 1847Gregorian', 'SNAC', 'w60p13nv', 'William Collins (painter)', '9 October 2017', 'BnF authorities', '105224408', 'William Collins']\n",
      "------------------\n",
      "place of death ['London', 'Wikimedia Commons']\n",
      "------------------\n",
      "spouse ['Harriet Geddes', 'Kindred Britain']\n",
      "------------------\n",
      "child ['Charles Allston Collins', 'Charles Allston Collins', 'Kindred Britain', 'Wilkie Collins', 'Wilkie Collins', 'Kindred Britain']\n",
      "------------------\n",
      "languages spoken, written or signed ['English']\n",
      "------------------\n",
      "occupation ['painter', 'etcher']\n",
      "------------------\n",
      "field of work ['art of painting']\n",
      "------------------\n",
      "work location ['Netherlands', '1828', 'RKDartists', '2 March 2018', 'https://rkd.nl/explore/artists/17780']\n",
      "------------------\n",
      "member of ['Royal Academy of Arts']\n",
      "------------------\n",
      "genre ['genre painting', 'landscape painting']\n",
      "------------------\n",
      "depicted by ['William Collins, R.A.']\n",
      "------------------\n",
      "described by source ['Nordisk familjebok', 'Small Brockhaus and Efron Encyclopedic Dictionary', 'Q21091454', 'Brockhaus and Efron Encyclopedic Dictionary', 'Q21091600', 'Dictionary of National Biography, 1885–1900', 'Collins, William (1788-1847) (DNB00)', 'The Nuttall Encyclopædia', 'Collins, William, R.A.', 'Malerwerke des neunzehnten Jahrhunderts: Beitrag zur Kunstgeschichte', 'Collins, William', 'Encyclopædia Britannica 11th edition', '1911 Encyclopædia Britannica/Collins, William']\n",
      "------------------\n",
      "on focus list of Wikimedia project ['WikiProject PCC Wikidata Pilot/Frick Art Reference Library', 'WikiProject New York Public Library']\n",
      "------------------\n",
      "has works in the collection ['Museo del Prado', 'Museo del Prado', 'https://www.wikidata.org/wiki/Q2623883#P5321', 'https://www.wikidata.org/wiki/Property:P5321#P2302', 'Tate', 'National Gallery of Art', 'National Gallery of Canada', 'Clark Art Institute', 'Children on the Beach', '25 February 2021', 'Walters Art Museum', 'Landscape with Children at Play', '12 March 2021', 'Yale Center for British Art', 'May Day', '12 March 2021', 'Walker Art Gallery', '13 March 2021', 'Returning from the Haunts of the Seafowl', 'National Gallery of Ireland', '30 May 2022', \"The Artist's Mother\", 'Victoria and Albert Museum', 'A Country Kitchen', '4 June 2023', 'Guildhall Art Gallery', 'The Pet Lamb', '4 June 2023', 'The Wilson', 'The Sale of the Pet Calf', '4 June 2023', 'Manchester Art Gallery', 'The Cottage Door', '5 June 2023', 'Whitworth Art Gallery', 'Coast Scene', '21 June 2023', 'National Museum Cardiff', 'Dedham Ferry', '23 June 2023', 'Brighton Museum & Art Gallery', 'Hastings, East Sussex', '24 June 2023', 'Royal Academy of Arts', 'Young Anglers', '16 July 2023', 'Bury Art Museum', 'The Minnow Catchers', '19 July 2023', 'Haworth Art Gallery', 'Cottage Hospitality', '29 July 2023', 'Russell-Cotes Art Gallery & Museum', 'Children Playing with Puppies', '19 August 2023', 'Wolverhampton Art Gallery', 'The Village Gossip', '26 August 2023', 'Shipley Art Gallery', 'The Return of the Fishing Boats', '20 September 2023', 'Leeds Art Gallery', 'The World or the Cloister', '18 October 2023', 'Touchstones Rochdale', 'The Sale of the Pet Lamb', '17 November 2023', 'Print Collection', 'New York Public Library Main Branch', 'https://web.archive.org/web/http://wallachprintsandphotos.nypl.org/catalog/316826', 'Harris Museum', \"The Mariner's Widow\", '5 May 2024', 'Williamson Art Gallery and Museum', 'Three Children under a Tree', '22 May 2024', 'Northampton Museum and Art Gallery', 'River Scene with Trees and Mountains', '27 May 2024', 'Kettering Museum and Art Gallery', \"The Day's Bag\", '30 May 2024', 'The Whitaker', 'Boys Gleaning', '30 May 2024', 'Ulster Museum', 'The Broom Seller', '17 June 2024', 'The Atkinson', 'Spinning Girl of Sorrento', '28 June 2024']\n",
      "------------------\n",
      "copyright status as a creator ['copyrights on works have expired', 'worldwide', '100 years or more after author(s) death', '9 May 2020']\n",
      "------------------\n",
      "artist files at ['Frick Art Research Library', '991003985809707141']\n",
      "------------------\n",
      "Commons Creator page ['William Collins']\n",
      "------------------\n",
      "Commons category ['William Collins']\n",
      "------------------\n",
      "VIAF ID ['28432019', 'English Wikipedia']\n",
      "------------------\n",
      "ISNI ['0000000066866254', 'International Standard Name Identifier']\n",
      "------------------\n",
      "Bibliothèque nationale de France ID ['105224408']\n",
      "------------------\n",
      "GND ID ['136705162', 'Historical Commission of the Bavarian Academy of Sciences']\n",
      "------------------\n",
      "Deutsche Biographie (GND) ID ['136705162']\n",
      "------------------\n",
      "DDB person ID ['136705162']\n",
      "------------------\n",
      "FAST ID ['104995']\n",
      "------------------\n",
      "J9U ID ['987007274324605171']\n",
      "------------------\n",
      "Union List of Artist Names ID ['500115372', 'Wikimedia Commons']\n",
      "------------------\n",
      "Library of Congress authority ID ['n82220770', 'English Wikipedia']\n",
      "------------------\n",
      "Libraries Australia ID ['36427261', 'Wikimedia Commons']\n",
      "------------------\n",
      "WorldCat Entities ID ['E39PBJgH9x7HFFgyvvgbQkjHmd', 'Library of Congress Authorities', 'n82220770', '24 April 2024']\n",
      "------------------\n",
      "AKL Online artist ID ['10168543']\n",
      "------------------\n",
      "Archive Site Trinity College Cambridge ID ['collins-william-john-thomas-1788-1847-landscape-and-genre-painter']\n",
      "------------------\n",
      "Archives at Yale agent ID ['people/71076']\n",
      "------------------\n",
      "Art Renewal Center artist ID ['2485']\n",
      "------------------\n",
      "Art UK artist ID ['collins-william-17881847', 'William Collins', '81', 'William Collins, 1788–1847 (English)', '30 January 2017']\n",
      "------------------\n",
      "Artcyclopedia artist ID ['collins_william']\n",
      "------------------\n",
      "Artist ID of the Department of Prints and Drawings of the Louvre ['3956-COLLINS-William', '2 October 2021']\n",
      "------------------\n",
      "Artnet artist ID ['william-collins']\n",
      "------------------\n",
      "Artsy artist ID ['william-collins']\n",
      "------------------\n",
      "askArt person ID ['9000368']\n",
      "------------------\n",
      "Athenaeum person ID ['7170']\n",
      "------------------\n",
      "Benezit ID ['B00040666']\n",
      "------------------\n",
      "Bridgeman artist ID ['850']\n",
      "------------------\n",
      "British Museum person or institution ID ['23336']\n",
      "------------------\n",
      "CERL Thesaurus ID ['cnp01157322', 'CERL Thesaurus']\n",
      "------------------\n",
      "Christie's creator ID ['16527']\n",
      "------------------\n",
      "Lex ID ['William_Collins']\n",
      "------------------\n",
      "DigitaltMuseum ID ['0210311629011']\n",
      "------------------\n",
      "Freebase ID ['/m/025wydk', 'Freebase Data Dumps', '28 October 2013']\n",
      "------------------\n",
      "Frick Art Research Library Artist File ID ['991003985809707141', 'Frick Art Research Library']\n",
      "------------------\n",
      "Google Arts & Culture entity ID ['m025wydk']\n",
      "------------------\n",
      "Invaluable.com person ID ['qayutmaial']\n",
      "------------------\n",
      "KulturNav-ID ['919c71a2-ddf0-4139-b81e-7bbbb08458c2', 'Kunstnere, arkitekter og designere i offentlige samlinger i Norge (Nasjonalmuseet for kunst, arkitektur og design)']\n",
      "------------------\n",
      "LBT person ID ['WiColli1847']\n",
      "------------------\n",
      "LIMIS person ID ['50000005931052']\n",
      "------------------\n",
      "McClintock and Strong Biblical Cyclopedia ID ['C/collins-william-(2)']\n",
      "------------------\n",
      "Met Constituent ID ['90447', 'William John Thomas Collins']\n",
      "------------------\n",
      "Museo del Prado artist ID ['ae86945d-a979-4ee7-bf63-fb5739bd9520', \"Mix'n'match\"]\n",
      "------------------\n",
      "National Gallery of Art artist ID ['10988']\n",
      "------------------\n",
      "National Gallery of Canada artist ID ['william-collins']\n",
      "------------------\n",
      "National Portrait Gallery (London) person ID ['mp00974']\n",
      "------------------\n",
      "NLA Trove people ID ['1255829']\n",
      "------------------\n",
      "Open Library ID ['OL1575734A']\n",
      "------------------\n",
      "Oxford Dictionary of National Biography ID ['5959']\n",
      "------------------\n",
      "Oxford Reference overview ID ['20110803095624680']\n",
      "------------------\n",
      "Philadelphia Museum of Art entity ID ['26916']\n",
      "------------------\n",
      "RA Collections ID ['5584', \"Mix'n'match\"]\n",
      "------------------\n",
      "RKDartists ID ['17780']\n",
      "------------------\n",
      "Royal Academy new identifier ['william-collins-ra']\n",
      "------------------\n",
      "SNAC ARK ID ['w60p13nv']\n",
      "------------------\n",
      "Tate artist ID ['105']\n",
      "------------------\n",
      "Te Papa agent ID ['476']\n",
      "------------------\n",
      "Treccani's Enciclopedia Italiana ID ['william-collins_res-6170d677-8bad-11dc-8e9d-0016357eee51', 'COLLINS, William', 'James Byam Shaw', '1931']\n",
      "------------------\n",
      "UK National Archives ID ['F32257']\n",
      "------------------\n",
      "Watercolour World artist ID ['william-collins']\n",
      "------------------\n",
      "Web Gallery of Art ID ['c/collins1']\n",
      "------------------\n",
      "WikiArt ID ['william-collins']\n",
      "------------------\n",
      "YCBA agent ID ['303']\n",
      "------------------\n",
      "Kindred Britain ID ['I15800']\n",
      "------------------\n",
      "Rodovid ID ['410147']\n",
      "------------------\n",
      "WikiTree person ID ['Collins-9138', 'William Collins (8 Sep 1788 - certain 17 Feb 1847)']\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 目标URL\n",
    "url = 'https://www.wikidata.org/wiki/Q2623883'\n",
    "\n",
    "# 发送GET请求\n",
    "response = requests.get(url)\n",
    "\n",
    "# 检查请求是否成功\n",
    "if response.status_code == 200:\n",
    "    # 使用BeautifulSoup解析HTML内容\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # print(soup)\n",
    "    titles=soup.find_all('div',class_='wikibase-statementgroupview-property')\n",
    "    tables=soup.find_all('div',class_='wikibase-statementlistview')\n",
    "    head=soup.find('span',class_='wikibase-title-label')\n",
    "    head_description=soup.find('div',class_='wikibase-entitytermsview-heading-description')\n",
    "    aliases=soup.find_all('li',class_='wikibase-entitytermsview-aliases-alias')\n",
    "    print(head.get_text(),',',head_description.get_text(),',',[alias.get_text() for alias in aliases])\n",
    "    print(len(tables))\n",
    "    print(len(titles))\n",
    "    # print(tables[0])\n",
    "    for title,table in zip(titles,tables):\n",
    "        bodys=table.find_all('div',class_='wikibase-snakview-body')\n",
    "        print(title.get_text().strip(),[x.get_text().strip() for x in bodys])\n",
    "        print(\"------------------\")\n",
    "        \n",
    "    \n",
    "    # 这里可以添加你想要提取的HTML元素的代码\n",
    "    # 例如，提取所有的标题\n",
    "    # items = soup.find_all('wikibase-statementgroupview-property-label')\n",
    "    # for item in items:\n",
    "    #     print(item.get_text())\n",
    "    # items = soup.find_all('wikibase-snakview-body')\n",
    "    # for item in items:\n",
    "    #     print(item.get_text())\n",
    "\n",
    "else:\n",
    "    print('请求失败，状态码：', response.status_code)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Practice: philosophical essay by Mao Zedong, , instance of: ['essay'], title: ['实践论 (Chinese)'], genre: ['essay'], author: ['Mao Zedong'], language of work or name: ['Chinese'], start time: ['July 1937'], publication date: ['1937'], Encyclopædia Britannica Online ID: ['topic/On-Practice'], Encyclopedia of China (Third Edition) ID: ['62290'], Freebase ID: ['/m/06p30rx']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def url2knowledge(url):\n",
    "    # 发送GET请求\n",
    "    # print(url)\n",
    "    headers={\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url,headers=headers)\n",
    "    knowledge=''\n",
    "    # 检查请求是否成功\n",
    "    if response.status_code == 200:\n",
    "        # 使用BeautifulSoup解析HTML内容\n",
    "        # print(response.text)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # print(soup)\n",
    "        titles=soup.find_all('div',class_='wikibase-statementgroupview-property')\n",
    "        tables=soup.find_all('div',class_='wikibase-statementlistview')\n",
    "        try:\n",
    "            assert len(titles)==len(tables)\n",
    "            # print(url)\n",
    "        except AssertionError as e:\n",
    "            print(e)\n",
    "        head=soup.find('span',class_='wikibase-title-label')\n",
    "        head_description=soup.find('div',class_='wikibase-entitytermsview-heading-description')\n",
    "        aliases=soup.find_all('li',class_='wikibase-entitytermsview-aliases-alias')\n",
    "        if head!=None:\n",
    "            knowledge+=head.get_text()\n",
    "            knowledge+=': '\n",
    "        if head_description!=None:\n",
    "            knowledge+=head_description.get_text()\n",
    "            knowledge+=', '\n",
    "        if aliases!=[]:\n",
    "            knowledge+=\"alias: \"\n",
    "            knowledge+=str([alias.get_text() for alias in aliases])\n",
    "        # print(head.get_text(),',',head_description.get_text(),',',[alias.get_text() for alias in aliases])\n",
    "\n",
    "        # print(len(tables))\n",
    "        # print(len(titles))\n",
    "        # print(tables[0])\n",
    "        for title,table in zip(titles,tables):\n",
    "            # bodys=table.find_all('div',class_='wikibase-snakview-body')\n",
    "            bodys=table.find_all('div',class_='wikibase-statementview-mainsnak-container')\n",
    "            knowledge+=\", \"\n",
    "            knowledge+=title.get_text().strip()\n",
    "            knowledge+=\": \"\n",
    "            knowledge+=str([x.find('div',class_='wikibase-statementview-mainsnak').get_text().strip() for x in bodys])\n",
    "            # print(title.get_text().strip(),[x.get_text().strip() for x in bodys])\n",
    "            # print(\"------------------\")\n",
    "        return knowledge\n",
    "    else:\n",
    "        print('请求失败，状态码：', response.status_code)\n",
    "        return url\n",
    "# knowledge=url2knowledge(\"https://www.wikidata.org/wiki/Q2623883\")\n",
    "# with open(\"./data/popQA_knowledge.txt\",'+a') as f:\n",
    "#     f.write(knowledge)\n",
    "#     f.write(\"\\n\")\n",
    "# with open()\n",
    "print(url2knowledge(\"http://www.wikidata.org/wiki/Q11452861\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/14267 [00:06<25:08:14,  6.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s_uri \u001b[38;5;129;01min\u001b[39;00m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms_uri\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# print(s_uri)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     prograss_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     knowledge\u001b[38;5;241m=\u001b[39m\u001b[43murl2knowledge\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_uri\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwiki\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# print(knowledge)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m knowledge\u001b[38;5;241m==\u001b[39ms_uri:\n",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m, in \u001b[0;36murl2knowledge\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21murl2knowledge\u001b[39m(url):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# 发送GET请求\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# print(url)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m     }\n\u001b[1;32m----> 9\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     knowledge\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# 检查请求是否成功\u001b[39;00m\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\site-packages\\requests\\sessions.py:725\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 725\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\site-packages\\requests\\sessions.py:725\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 725\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\site-packages\\requests\\sessions.py:266\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[1;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    267\u001b[0m         req,\n\u001b[0;32m    268\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    269\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    270\u001b[0m         verify\u001b[38;5;241m=\u001b[39mverify,\n\u001b[0;32m    271\u001b[0m         cert\u001b[38;5;241m=\u001b[39mcert,\n\u001b[0;32m    272\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    273\u001b[0m         allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madapter_kwargs,\n\u001b[0;32m    275\u001b[0m     )\n\u001b[0;32m    277\u001b[0m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcookies, prepared_request, resp\u001b[38;5;241m.\u001b[39mraw)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32md:\\APP\\Anaconda3\\envs\\pytorch2_1\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset,Dataset,load_from_disk\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import gzip,json\n",
    "import time\n",
    "dataset=load_from_disk(\"D:\\BaiduSyncdisk\\AI-Security-Evaluation_RAG\\data\\PopQA\")\n",
    "prograss_bar=tqdm(total=len(dataset['s_uri']))\n",
    "# print(url2knowledge(str(dataset['s_uri'][0])))\n",
    "for s_uri in dataset['s_uri']:\n",
    "    # print(s_uri)\n",
    "    prograss_bar.update(1)\n",
    "    knowledge=url2knowledge(s_uri.replace(\"entity\",\"wiki\"))\n",
    "    # print(knowledge)\n",
    "    if knowledge==s_uri:\n",
    "        print(knowledge)\n",
    "        continue\n",
    "    with open(\"D:\\BaiduSyncdisk\\AI-Security-Evaluation_RAG\\data\\popQA_knowledge.txt\",'+a') as f:\n",
    "        f.write(knowledge)\n",
    "        f.write(\"\\n\")\n",
    "    # time.sleep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,11,3):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
